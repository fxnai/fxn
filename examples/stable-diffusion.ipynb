{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion Sample\n",
    "This notebook provides an overview of how you can bring your own AI prediction functions, or \"predictors\", to Function. The first thing to note is this cell: if the first cell in your notebook is a Markdown cell, Function will pull it out as a README and display the cell's contents on [fxn.ai](https://fxn.ai/explore)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Predictor\n",
    "Now, let's create a prediction function that runs the popular Stable Diffusion model. The predictor will accept a `prompt` string and return an image. We'll be using the Stable Diffusion model from [the HuggingFace library](https://huggingface.co/). First, we have to install the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch, HuggingFace Transformers, and HuggingFace Diffusers\n",
    "%pip install torch transformers diffusers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that in Function, installing dependencies is as simple as using the built-in magic functionality in IPython/Jupyter. You can also install system dependencies using:\n",
    "```py\n",
    "# Installing a system library\n",
    "!apt-get install ...\n",
    "```\n",
    "\n",
    "Finally, let's write the actual predictor code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "from torch import float16\n",
    "\n",
    "# Create a pipeline\n",
    "# This code will run while provisioning the predictor, meaning that models can be downloaded at provisioning-time\n",
    "pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=float16)\n",
    "\n",
    "# Define our predict function\n",
    "def predict (prompt: str):\n",
    "    \"\"\"\n",
    "    Generate an image from a text prompt using StableDiffusion.\n",
    "\n",
    "    Parameters:\n",
    "        prompt (str): Input prompt.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: Generated image.\n",
    "    \"\"\"\n",
    "    # This predictor will be accelerated with an Nvidia A100 GPU, so move the pipeline over\n",
    "    pipeline.to(\"cuda\")\n",
    "    # Generate an image\n",
    "    result = pipeline(prompt).images[0]\n",
    "    # Return resulting image\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Predictor\n",
    "Testing a predictor is as simple as running your `predict` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"an astronaut riding a horse on Mars\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Predictor on Function\n",
    "To create the predictor on Function, open a terminal and run the following command:\n",
    "```sh\n",
    "fxn create @[your Function username]/stable-diffusion /path/to/stable-diffusion.ipynb --acceleration A100\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
